{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from ovejero import forward_modeling, model_trainer\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "\n",
    "def NOTIMPLEMENTED():\n",
    "    raise NotImplementedError('Must specify config/save path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Forward Modeling to a BNN Posterior\n",
    "\n",
    "__Author:__ Sebastian Wagner-Carena\n",
    "\n",
    "__Last Run:__ 08/15/2020\n",
    "\n",
    "__Goals:__ Learn how to compare the performance of the BNN model to a forward modeling approach\n",
    "\n",
    "__Before running this notebook:__ Run the Train_Toy_Model notebook to understand how to train a model. Then train a model with whatever configuration you want. You will have to add the path to the config file in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, all we have to do is load up our model weights and run it on a specific image in the validation set. Thankfully, that's pretty easy to do with the ForwardModeling class. If you don't have a GPU, generating 10000 samples for one image should still be managable but will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First specify the config path\n",
    "config_path = NOTIMPLEMENTED()\n",
    "\n",
    "# Check that the config has what you need\n",
    "cfg = model_trainer.load_config(config_path)\n",
    "\n",
    "# The ForwardModeling will do all the heavy lifting of preparing the model from the configuration file,\n",
    "# initializing the validation dataset, and providing outputs correctly marginalized over the BNN uncertainties.\n",
    "fow_model = forward_modeling.ForwardModel(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to select an image for the forward modeling comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 25\n",
    "fow_model.select_image(image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our forward modeling. I would recommend saving the weights in case you want to stop and restart later. The 100 steps we do here aren't going to be enough for convergence, but for the demo this will be good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our sampler for the three models\n",
    "walker_ratio = 50\n",
    "n_samps = 100\n",
    "save_path_chains = os.path.join(root_path,'demos/demo_fow_model_chains.h5')\n",
    "\n",
    "fow_model.initialize_sampler(walker_ratio,save_path_chains)\n",
    "fow_model.run_sampler(n_samps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the chains as a quick visual inspection that things are working. Feel free to some more advanced tests on the chains as well (for example take a look at the hierarchical inference notebook). Given that we've only done 100 steps, you shouldn't see anything that looks like convergence. The solid black line is the true parameter values. Feel free to put in larger numbers for good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "burnin = 0\n",
    "fow_model.plot_chains(burnin=burnin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want BNN samples of this one lens to make a comparison. Since we're only running the analysis on one lens we can afford to do some denser sampling (say 10k samples). Note, if you've only run 100 forward modeling steps and trained the BNN, the BNN will probably look a lot better than the forward model here. That's just a trick of convergence, run the forward model for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "sample_save_dir = os.path.join(root_path,'demos/fow_model_bnn_samps')\n",
    "# Now let's look at the corner plot of the parameters we care about (the lens parameters)\n",
    "color_map = ['#d95f02','#7570b3','#000000']\n",
    "truth_color = '#e7298a'\n",
    "\n",
    "# For an example of how to specify plot limits see the forward modeling plotting notebook in the paper folder. The\n",
    "# standard we use here is the same as for the corner.corner package.\n",
    "plot_limits = None\n",
    "fontsize = 20\n",
    "\n",
    "fig = fow_model.plot_posterior_contours(burnin,num_samples,sample_save_dir=sample_save_dir,\n",
    "                                            color_map=color_map,plot_limits=plot_limits,truth_color=truth_color,\n",
    "                                            save_fig_path=None,show_plot=False,add_legend=False,\n",
    "                                            fontsize=fontsize)\n",
    "\n",
    "handles = [Line2D([0], [0], color=color_map[0], lw=10),\n",
    "           Line2D([0], [0], color=color_map[1], lw=10)]\n",
    "fig.legend(handles,[r'Full BNN 0.1% Dropout','Forward Modeling'],loc=(0.525,0.73),\n",
    "           fontsize=fontsize,framealpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the files we generated during the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('demo_fow_model_chains.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
