{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from ovejero import forward_modeling, model_trainer\n",
    "import os\n",
    "import corner\n",
    "\n",
    "# Modifies the paths in the config to agree with the paths being used on the current computer.\n",
    "def recursive_str_checker(cfg_dict):\n",
    "    for key in cfg_dict:\n",
    "        if isinstance(cfg_dict[key],str):\n",
    "            cfg_dict[key] = cfg_dict[key].replace('/home/swagnercarena/ovejero/',root_path)\n",
    "        if isinstance(cfg_dict[key],dict):\n",
    "            recursive_str_checker(cfg_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Performance to Forward Modeling\n",
    "\n",
    "__Author:__ Sebastian Wagner-Carena\n",
    "\n",
    "__Last Run:__ 07/27/2020\n",
    "\n",
    "__Goals:__ Compare the performance of the BNN model to a forward modeling approach\n",
    "\n",
    "__Before running this notebook:__ You will have to download and unzip the bnn samples, chains, and datasets that can be found here (TODO). Because we already have the BNN samples, the model weights are not neccesary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Full and GMM results for 0.1% Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load all of our forward modeling and BNN samples for all three of our BNN models. Our forward modeling is done directly through lenstronomy. To get lenstronomy to load the weights for the forward modeling, we will have to sample once. This should take at most a second or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd()[:-5]\n",
    "\n",
    "# Grab the config paths for our three BNN models\n",
    "nn1_config_path = root_path + 'configs/nn1_hr.json'\n",
    "nn2_config_path = root_path + 'configs/nn2_slr.json'\n",
    "nn3_config_path = root_path + 'configs/nn3_slr.json'\n",
    "\n",
    "# Load the config for our three models.\n",
    "nn1_cfg = model_trainer.load_config(nn1_config_path)\n",
    "nn2_cfg = model_trainer.load_config(nn2_config_path)\n",
    "nn3_cfg = model_trainer.load_config(nn3_config_path)\n",
    "\n",
    "recursive_str_checker(nn1_cfg)\n",
    "recursive_str_checker(nn2_cfg)\n",
    "recursive_str_checker(nn3_cfg)\n",
    "\n",
    "# Samples are already generated so we don't need the model weights\n",
    "lite_class = True\n",
    "\n",
    "fow_model_nn1 = forward_modeling.ForwardModel(nn1_cfg,lite_class=lite_class)\n",
    "fow_model_nn2 = forward_modeling.ForwardModel(nn2_cfg,lite_class=lite_class)\n",
    "fow_model_nn3 = forward_modeling.ForwardModel(nn3_cfg,lite_class=lite_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to select the image we'll use for our forward modeling. So long as you've downloaded the datasets or generated them using the baobab configs provided in this git repo, image index 40 will have the correct meaning. This should print out the same image and information 3 times. Note the random noise is fixed by a set seed to ensure that the forward modeling and the BNN see the exact same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select the image we want to forward model.\n",
    "image_index = 40\n",
    "fow_model_nn1.select_image(image_index)\n",
    "fow_model_nn2.select_image(image_index)\n",
    "fow_model_nn3.select_image(image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to initialize our three forward modeling samplers. They are all pulling the same weights (since the forward model doesn't care which BNN was used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our sampler for the three models\n",
    "walker_ratio = 50\n",
    "n_samps = 1\n",
    "save_path_chains = os.path.join(root_path,'forward_modeling/%s.h5'%(fow_model_nn1.true_values['img_filename'][:-4]))\n",
    "\n",
    "fow_model_nn1.initialize_sampler(walker_ratio,save_path_chains)\n",
    "fow_model_nn1.run_sampler(n_samps)\n",
    "fow_model_nn2.initialize_sampler(walker_ratio,save_path_chains)\n",
    "fow_model_nn2.run_sampler(n_samps)\n",
    "fow_model_nn3.initialize_sampler(walker_ratio,save_path_chains)\n",
    "fow_model_nn3.run_sampler(n_samps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the path to the pre-run BNN samples. If you have the weights downloaded, feel free to rerun this on a GPU. Even without a GPU it should only take tens of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "burnin = 2000\n",
    "\n",
    "sample_save_dir_nn1 = os.path.join(root_path,'forward_modeling/nn1_%s_samps'%(\n",
    "    fow_model_nn1.true_values['img_filename'][:-4]))\n",
    "sample_save_dir_nn2 = os.path.join(root_path,'forward_modeling/nn2_%s_samps'%(\n",
    "    fow_model_nn1.true_values['img_filename'][:-4]))\n",
    "sample_save_dir_nn3 = os.path.join(root_path,'forward_modeling/nn3_%s_samps'%(\n",
    "    fow_model_nn1.true_values['img_filename'][:-4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the comparison of the forward modeling posterior and the full / GMM posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the corner plot of the parameters we care about (the lens parameters)\n",
    "color_map = ['#d95f02','#7570b3','#000000']\n",
    "truth_color = '#e7298a'\n",
    "plot_limits = [(0.03,0.09),(-0.06,0.00),(0.03,0.06),(-0.06,-0.03),(-0.03,0.04),(-0.26,-0.19),(1.6,1.85),\n",
    "              (-0.04,-0.008)]\n",
    "save_fig_path = 'figures/fow_model_comp.pdf'\n",
    "fontsize = 20\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "fig = fow_model_nn2.plot_posterior_contours(burnin,num_samples,sample_save_dir=sample_save_dir_nn2,\n",
    "                                            color_map=color_map,plot_limits=plot_limits,truth_color=truth_color,\n",
    "                                            save_fig_path=None,show_plot=False,plot_fow_model=False,add_legend=False,\n",
    "                                            fontsize=fontsize)\n",
    "fig = fow_model_nn3.plot_posterior_contours(burnin,num_samples,sample_save_dir=sample_save_dir_nn3,\n",
    "                                            color_map=color_map[1:],plot_limits=plot_limits,truth_color=truth_color,\n",
    "                                            save_fig_path=None,fig=fig,show_plot=False,add_legend=False,\n",
    "                                            fontsize=fontsize)\n",
    "\n",
    "handles = [Line2D([0], [0], color=color_map[0], lw=10),\n",
    "           Line2D([0], [0], color=color_map[1], lw=10),\n",
    "           Line2D([0], [0], color=color_map[2], lw=10)]\n",
    "fig.legend(handles,[r'Full BNN 0.1% Dropout',r'GMM BNN 0.1% Dropout','Forward Modeling'],loc=(0.525,0.73),\n",
    "           fontsize=20,framealpha=1.0)\n",
    "fig.savefig(save_fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison for Diagonal BNN 30% Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to generate the same plot as above, but now with the diagaonal BNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now let's look at the corner plot of the parameters we care about (the lens parameters)\n",
    "color_map = ['#1b9e77','#000000']\n",
    "truth_color = '#e7298a'\n",
    "plot_limits = [(0.00,0.09),(-0.05,0.04),(0.01,0.08),(-0.08,-0.01),(-0.07,0.04),(-0.34,-0.16),(1.65,2.1),\n",
    "              (-0.08,0.01)]\n",
    "save_fig_path = 'figures/fow_model_comp_diag.pdf'\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "fig = fow_model_nn1.plot_posterior_contours(burnin,num_samples,sample_save_dir=sample_save_dir_nn1,\n",
    "                                            color_map=color_map,plot_limits=plot_limits,truth_color=truth_color,\n",
    "                                            save_fig_path=None,show_plot=False,add_legend=False,fontsize=fontsize)\n",
    "\n",
    "handles = [Line2D([0], [0], color=color_map[0], lw=10),\n",
    "           Line2D([0], [0], color=color_map[1], lw=10)]\n",
    "fig.legend(handles,[r'Diagonal BNN 30% Dropout','Forward Modeling'],loc=(0.54,0.73),fontsize=20,framealpha=1.0)\n",
    "fig.savefig(save_fig_path)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
